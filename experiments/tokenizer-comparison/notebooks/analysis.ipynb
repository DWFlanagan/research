{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer Comparison Analysis\n",
    "\n",
    "This notebook provides interactive analysis and visualization of tokenizer comparison results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from visualization import generate_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results\n",
    "\n",
    "Load the results from a previous experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results_dir = Path('../results')\n",
    "results_file = results_dir / 'results.json'\n",
    "\n",
    "with open(results_file) as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Loaded {len(df)} evaluation results\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by tokenizer\n",
    "print(\"Average metrics by tokenizer:\\n\")\n",
    "print(df.groupby('tokenizer')[[\n",
    "    'tokens_per_1000_chars',\n",
    "    'tokens_per_100_words',\n",
    "    'reconstruction_similarity',\n",
    "    'throughput_tokens_per_sec'\n",
    "]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "### Token Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tokens per 1000 chars\n",
    "plt.figure(figsize=(12, 6))\n",
    "grouped = df.groupby('tokenizer')['tokens_per_1000_chars'].mean().sort_values()\n",
    "grouped.plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Tokens per 1000 Characters')\n",
    "plt.ylabel('Tokenizer')\n",
    "plt.title('Token Efficiency Comparison')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction similarity\n",
    "plt.figure(figsize=(12, 6))\n",
    "tokenizers = df['tokenizer'].unique()\n",
    "data = [df[df['tokenizer'] == tok]['reconstruction_similarity'].values for tok in tokenizers]\n",
    "\n",
    "plt.boxplot(data, labels=tokenizers, patch_artist=True)\n",
    "plt.ylabel('Reconstruction Similarity')\n",
    "plt.xlabel('Tokenizer')\n",
    "plt.title('Reconstruction Fidelity')\n",
    "plt.ylim([0, 1.05])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throughput Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput\n",
    "plt.figure(figsize=(12, 6))\n",
    "grouped = df.groupby('tokenizer')['throughput_tokens_per_sec'].mean().sort_values(ascending=False)\n",
    "grouped.plot(kind='bar', color='coral')\n",
    "plt.ylabel('Throughput (tokens/sec)')\n",
    "plt.xlabel('Tokenizer')\n",
    "plt.title('Tokenization Speed')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Examples\n",
    "\n",
    "Load and explore tokenization examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentence examples if available\n",
    "examples_file = results_dir / 'sentence_examples.json'\n",
    "if examples_file.exists():\n",
    "    with open(examples_file) as f:\n",
    "        examples = json.load(f)\n",
    "    \n",
    "    # Show first example\n",
    "    first_key = list(examples.keys())[0]\n",
    "    first_example = examples[first_key][0]\n",
    "    \n",
    "    print(f\"Example from {first_key}:\\n\")\n",
    "    print(f\"Text: {first_example['text']}\")\n",
    "    print(f\"\\nTokens ({first_example['token_count']}): {first_example['tokens'][:20]}...\")\n",
    "else:\n",
    "    print(\"No sentence examples found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Analysis\n",
    "\n",
    "Add your own analysis and visualizations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
